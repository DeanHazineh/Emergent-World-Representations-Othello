{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deanhazineh/anaconda3/envs/emergent_world/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from EWOthello.data.othello import *\n",
    "\n",
    "from EWOthello.mingpt.dataset import CharDataset # AK's mingpt \n",
    "from EWOthello.mingpt.model import GPT, GPTConfig\n",
    "from EWOthello.mingpt.trainer import Trainer, TrainerConfig\n",
    "from EWOthello.mingpt.utils import set_seed, sample\n",
    "\n",
    "set_seed(44)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some intuition about training times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 14.64 GB: 100%|██████████| 231/231 [00:45<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplicating...\n",
      "Deduplicating finished with 23096133 games left\n",
      "Using 20 million for training, 3096133 for validation\n",
      "Dataset created has 20000000 sequences, 61 unique words.\n"
     ]
    }
   ],
   "source": [
    "othello = get(ood_num=-1, data_root=None)\n",
    "train_dataset = CharDataset(othello) \n",
    "\n",
    "# # Example of the training data pair (blocked results format)\n",
    "# # Note that values is not the board number but is the board number converted to dictionary index!\n",
    "# x, y = train_dataset[5]\n",
    "# print(x)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=2, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 39062: train loss 2.31852. lr 1.000000e-04: 100%|██████████| 39063/39063 [1:00:36<00:00, 10.74it/s] \n",
      "epoch 2 iter 39062: train loss 2.24934. lr 2.000000e-04: 100%|██████████| 39063/39063 [1:00:19<00:00, 10.79it/s] \n",
      "epoch 3 iter 39062: train loss 2.23907. lr 3.000000e-04: 100%|██████████| 39063/39063 [1:00:53<00:00, 10.69it/s]\n",
      "epoch 4 iter 39062: train loss 2.23784. lr 4.000000e-04: 100%|██████████| 39063/39063 [1:00:16<00:00, 10.80it/s] \n",
      "epoch 5 iter 39062: train loss 2.23877. lr 5.000000e-04: 100%|██████████| 39063/39063 [1:00:50<00:00, 10.70it/s] \n",
      "epoch 6 iter 39062: train loss 2.22996. lr 3.750000e-04: 100%|██████████| 39063/39063 [1:00:15<00:00, 10.80it/s] \n",
      "epoch 7 iter 39062: train loss 2.20682. lr 1.250000e-04: 100%|██████████| 39063/39063 [1:00:50<00:00, 10.70it/s]\n",
      "epoch 8 iter 39062: train loss 2.20407. lr 5.000000e-05: 100%|██████████| 39063/39063 [1:00:17<00:00, 10.80it/s] \n"
     ]
    }
   ],
   "source": [
    "# On the full synthetic dataset, we can estimate an order of 3+ hours on single gpu with settings below\n",
    "# It would be reasonable to train on cluster with these settings and this architecture and we could likely train \n",
    "# the smaller real world dataset locally\n",
    "max_epochs = 8\n",
    "savepath = \"../EWOthello/ckpts/\"\n",
    "\n",
    "t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=max_epochs, \n",
    "    batch_size=512*1, \n",
    "    learning_rate=5e-4,\n",
    "    lr_decay=True, \n",
    "    warmup_tokens=len(train_dataset)*train_dataset.block_size*5, \n",
    "    final_tokens=len(train_dataset)*train_dataset.block_size*max_epochs,\n",
    "    num_workers=0, \n",
    "    ckpt_path=savepath + f\"gpt_at{t_start}.ckpt\", \n",
    ")\n",
    "trainer = Trainer(model, train_dataset, None, tconf)\n",
    "device = trainer.device\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99.73% pass rate: 58785/58947 among all searched nodes: 100%|██████████| 1000/1000 [01:50<00:00,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.73% pass rate: 58785/58947 among all searched nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_dat = othello.val\n",
    "print(len(val_dat))\n",
    "\n",
    "total_nodes=0\n",
    "success_nodes = 0\n",
    "bar = tqdm(val_dat[:1000])\n",
    "for game in bar:\n",
    "    len_game = len(game)\n",
    "    for len_partial_game in range(1, len_game):\n",
    "        total_nodes += 1\n",
    "        context = game[:len_partial_game]\n",
    "        x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None, ...].to(device)\n",
    "        y = sample(model, x, 1, temperature=1.0)[0]\n",
    "        completion = [train_dataset.itos[int(i)] for i in y]\n",
    "        #completion = [train_dataset.itos[int(i)] for i in y if i != -1]\n",
    "        try:\n",
    "            OthelloBoardState().update(completion, prt=False)\n",
    "        except Exception:\n",
    "            pass\n",
    "        else:\n",
    "            success_nodes += 1\n",
    "    bar.set_description(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")\n",
    "    \n",
    "print(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probe loaded checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)\n",
    "\n",
    "load_res = model.load_state_dict(torch.load(\"../EWOthello/ckpts/gpt_synthetic.ckpt\"))\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99.99% pass rate: 58940/58947 among all searched nodes: 100%|██████████| 1000/1000 [04:23<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99% pass rate: 58940/58947 among all searched nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_dat = othello.val\n",
    "print(len(val_dat))\n",
    "\n",
    "total_nodes=0\n",
    "success_nodes = 0\n",
    "bar = tqdm(val_dat[:1000])\n",
    "for game in bar:\n",
    "    len_game = len(game)\n",
    "    for len_partial_game in range(1, len_game):\n",
    "        total_nodes += 1\n",
    "        context = game[:len_partial_game]\n",
    "        x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None, ...].to(device)\n",
    "        y = sample(model, x, 1, temperature=1.0)[0]\n",
    "        completion = [train_dataset.itos[int(i)] for i in y]\n",
    "        #completion = [train_dataset.itos[int(i)] for i in y if i != -1]\n",
    "        try:\n",
    "            OthelloBoardState().update(completion, prt=False)\n",
    "        except Exception:\n",
    "            pass\n",
    "        else:\n",
    "            success_nodes += 1\n",
    "    bar.set_description(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")\n",
    "    \n",
    "print(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emergent_world",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
