{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from EWOthello.data.othello import *\n",
    "\n",
    "from EWOthello.mingpt.dataset import CharDataset # AK's mingpt \n",
    "from EWOthello.mingpt.model import GPT, GPTConfig\n",
    "from EWOthello.mingpt.trainer import Trainer, TrainerConfig\n",
    "from EWOthello.mingpt.utils import set_seed, sample\n",
    "\n",
    "set_seed(44)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some intuition about training times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max num files: 230; Use_num: 10\n",
      "['gen10e5__20220324_165952.pickle', 'gen10e5__20220324_154919.pickle', 'gen10e5__20220324_164123.pickle', 'gen10e5__20220324_154043.pickle', 'gen10e5__20220324_155251.pickle', 'gen10e5__20220324_160016.pickle', 'gen10e5__20220324_165748.pickle', 'gen10e5__20220324_154002.pickle', 'gen10e5__20220324_155241.pickle', 'gen10e5__20220324_165707.pickle']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 2.324 GB: 100%|██████████| 10/10 [00:01<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplicating...\n",
      "Deduplicating finished with 999947 games left\n",
      "Using 20 million for training, 0 for validation\n",
      "Dataset created has 999947 sequences, 61 unique words.\n",
      "tensor([20, 19, 18, 10,  2,  1, 27,  3, 41, 26, 25, 21, 11, 42, 22, 14, 34, 17,\n",
      "        13, 23, 50, 39, 33, 43, 36, 31, 28, 51, 15, 12,  9, 35, 30,  8, 47, 16,\n",
      "        40, 48, 32, 46, 60, 49, 57, 55, 29,  5, 45, 38, 37, 58, 24, 59, 52, 54,\n",
      "        44, 53,  6,  7,  4])\n",
      "tensor([19, 18, 10,  2,  1, 27,  3, 41, 26, 25, 21, 11, 42, 22, 14, 34, 17, 13,\n",
      "        23, 50, 39, 33, 43, 36, 31, 28, 51, 15, 12,  9, 35, 30,  8, 47, 16, 40,\n",
      "        48, 32, 46, 60, 49, 57, 55, 29,  5, 45, 38, 37, 58, 24, 59, 52, 54, 44,\n",
      "        53,  6,  7,  4, 56])\n"
     ]
    }
   ],
   "source": [
    "othello = get(ood_num=-1, data_root=None)\n",
    "train_dataset = CharDataset(othello) \n",
    "\n",
    "# Example of the training data pair (blocked results format)\n",
    "# Note that values is not the board number but is the board number converted to dictionary index!\n",
    "x, y = train_dataset[5]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=2, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 976: train loss 2.71466. lr 1.000000e-04: 100%|██████████| 977/977 [02:53<00:00,  5.63it/s]\n",
      "epoch 2 iter 976: train loss 2.53513. lr 2.000000e-04: 100%|██████████| 977/977 [02:55<00:00,  5.58it/s]\n",
      "epoch 3 iter 976: train loss 2.43578. lr 3.000000e-04: 100%|██████████| 977/977 [02:54<00:00,  5.60it/s]\n",
      "epoch 4 iter 976: train loss 2.37902. lr 4.000000e-04: 100%|██████████| 977/977 [02:53<00:00,  5.63it/s]\n",
      "epoch 5 iter 976: train loss 2.35797. lr 5.000000e-04: 100%|██████████| 977/977 [02:56<00:00,  5.55it/s]\n",
      "epoch 6 iter 976: train loss 2.32269. lr 4.983096e-04: 100%|██████████| 977/977 [02:56<00:00,  5.54it/s]\n",
      "epoch 7 iter 976: train loss 2.30786. lr 4.932612e-04: 100%|██████████| 977/977 [02:54<00:00,  5.61it/s]\n",
      "epoch 8 iter 976: train loss 2.30639. lr 4.849232e-04: 100%|██████████| 977/977 [02:56<00:00,  5.54it/s]\n",
      "epoch 9 iter 976: train loss 2.29102. lr 4.734082e-04: 100%|██████████| 977/977 [02:55<00:00,  5.57it/s]\n",
      "epoch 10 iter 976: train loss 2.27887. lr 4.588720e-04: 100%|██████████| 977/977 [02:56<00:00,  5.54it/s]\n",
      "epoch 11 iter 976: train loss 2.26829. lr 4.415111e-04: 100%|██████████| 977/977 [02:54<00:00,  5.61it/s]\n",
      "epoch 12 iter 976: train loss 2.26842. lr 4.215604e-04: 100%|██████████| 977/977 [02:56<00:00,  5.53it/s]\n",
      "epoch 13 iter 976: train loss 2.26120. lr 3.992896e-04: 100%|██████████| 977/977 [02:55<00:00,  5.57it/s]\n",
      "epoch 14 iter 976: train loss 2.26042. lr 3.750000e-04: 100%|██████████| 977/977 [02:56<00:00,  5.53it/s]\n",
      "epoch 15 iter 976: train loss 2.25425. lr 3.490199e-04: 100%|██████████| 977/977 [02:55<00:00,  5.57it/s]\n",
      "epoch 16 iter 976: train loss 2.26233. lr 3.217008e-04: 100%|██████████| 977/977 [02:55<00:00,  5.58it/s]\n",
      "epoch 17 iter 976: train loss 2.24480. lr 2.934120e-04: 100%|██████████| 977/977 [02:55<00:00,  5.57it/s]\n",
      "epoch 18 iter 976: train loss 2.24449. lr 2.645362e-04: 100%|██████████| 977/977 [02:55<00:00,  5.57it/s]\n",
      "epoch 19 iter 976: train loss 2.23940. lr 2.354638e-04: 100%|██████████| 977/977 [02:55<00:00,  5.57it/s]\n",
      "epoch 20 iter 976: train loss 2.22547. lr 2.065880e-04: 100%|██████████| 977/977 [02:56<00:00,  5.53it/s]\n",
      "epoch 21 iter 976: train loss 2.23820. lr 1.782992e-04: 100%|██████████| 977/977 [02:55<00:00,  5.57it/s]\n",
      "epoch 22 iter 976: train loss 2.22573. lr 1.509801e-04: 100%|██████████| 977/977 [02:54<00:00,  5.61it/s]\n",
      "epoch 23 iter 976: train loss 2.23239. lr 1.250000e-04: 100%|██████████| 977/977 [02:56<00:00,  5.53it/s]\n",
      "epoch 24 iter 976: train loss 2.22046. lr 1.007104e-04: 100%|██████████| 977/977 [02:55<00:00,  5.57it/s]\n",
      "epoch 25 iter 976: train loss 2.22367. lr 7.843959e-05: 100%|██████████| 977/977 [02:56<00:00,  5.53it/s]\n",
      "epoch 26 iter 976: train loss 2.22011. lr 5.848889e-05: 100%|██████████| 977/977 [02:56<00:00,  5.53it/s]\n",
      "epoch 27 iter 976: train loss 2.21714. lr 5.000000e-05: 100%|██████████| 977/977 [02:54<00:00,  5.61it/s]\n",
      "epoch 28 iter 976: train loss 2.21709. lr 5.000000e-05: 100%|██████████| 977/977 [02:56<00:00,  5.53it/s]\n",
      "epoch 29 iter 976: train loss 2.21332. lr 5.000000e-05: 100%|██████████| 977/977 [02:55<00:00,  5.57it/s]\n",
      "epoch 30 iter 976: train loss 2.21587. lr 5.000000e-05: 100%|██████████| 977/977 [02:55<00:00,  5.57it/s]\n",
      "epoch 31 iter 976: train loss 2.21762. lr 5.000000e-05: 100%|██████████| 977/977 [02:56<00:00,  5.53it/s]\n",
      "epoch 32 iter 976: train loss 2.21924. lr 5.000000e-05: 100%|██████████| 977/977 [02:56<00:00,  5.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# On the full synthetic dataset, we can estimate an order of 3+ hours on single gpu with settings below\n",
    "# It would be reasonable to train on cluster with these settings and this architecture and we could likely train \n",
    "# the smaller real world dataset locally\n",
    "max_epochs = 32\n",
    "savepath = \"../EWOthello/ckpts/\"\n",
    "\n",
    "t_start = time.strftime(\"_%Y%m%d_%H%M%S\")\n",
    "tconf = TrainerConfig(\n",
    "    max_epochs=max_epochs, \n",
    "    batch_size=1024, \n",
    "    learning_rate=5e-4,\n",
    "    lr_decay=True, \n",
    "    warmup_tokens=len(train_dataset)*train_dataset.block_size*5, \n",
    "    final_tokens=len(train_dataset)*train_dataset.block_size*max_epochs,\n",
    "    num_workers=0, \n",
    "    ckpt_path=savepath + f\"gpt_at{t_start}.ckpt\", \n",
    ")\n",
    "trainer = Trainer(model, train_dataset, None, tconf)\n",
    "device = trainer.device\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/deanhazineh/Research/emergent_world_representation/dev_code/test_gpt_training.ipynb Cell 6\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/deanhazineh/Research/emergent_world_representation/dev_code/test_gpt_training.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m             success_nodes \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/deanhazineh/Research/emergent_world_representation/dev_code/test_gpt_training.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     bar\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msuccess_nodes\u001b[39m/\u001b[39mtotal_nodes\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m% pass rate: \u001b[39m\u001b[39m{\u001b[39;00msuccess_nodes\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mtotal_nodes\u001b[39m}\u001b[39;00m\u001b[39m among all searched nodes\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/deanhazineh/Research/emergent_world_representation/dev_code/test_gpt_training.ipynb#W5sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msuccess_nodes\u001b[39m/\u001b[39mtotal_nodes\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m% pass rate: \u001b[39m\u001b[39m{\u001b[39;00msuccess_nodes\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mtotal_nodes\u001b[39m}\u001b[39;00m\u001b[39m among all searched nodes\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "val_dat = othello.val\n",
    "print(len(val_dat))\n",
    "\n",
    "total_nodes=0\n",
    "success_nodes = 0\n",
    "bar = tqdm(val_dat[:1000])\n",
    "for game in bar:\n",
    "    len_game = len(game)\n",
    "    for len_partial_game in range(1, len_game):\n",
    "        total_nodes += 1\n",
    "        context = game[:len_partial_game]\n",
    "        x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None, ...].to(device)\n",
    "        y = sample(model, x, 1, temperature=1.0)[0]\n",
    "        completion = [train_dataset.itos[int(i)] for i in y]\n",
    "        #completion = [train_dataset.itos[int(i)] for i in y if i != -1]\n",
    "        try:\n",
    "            OthelloBoardState().update(completion, prt=False)\n",
    "        except Exception:\n",
    "            pass\n",
    "        else:\n",
    "            success_nodes += 1\n",
    "    bar.set_description(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")\n",
    "    \n",
    "print(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probe loaded checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 364.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created has 100 sequences, 61 unique words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "othello = get(ood_num=100, data_root=None)\n",
    "train_dataset = CharDataset(othello) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size, n_layer=8, n_head=8, n_embd=512)\n",
    "model = GPT(mconf)\n",
    "load_res = model.load_state_dict(torch.load(\"../EWOthello/ckpts/gpt_synthetic.ckpt\"))\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99.99% pass rate: 58940/58947 among all searched nodes: 100%|██████████| 1000/1000 [04:23<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99% pass rate: 58940/58947 among all searched nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_dat = othello.val\n",
    "print(len(val_dat))\n",
    "\n",
    "total_nodes=0\n",
    "success_nodes = 0\n",
    "bar = tqdm(val_dat[:1000])\n",
    "for game in bar:\n",
    "    len_game = len(game)\n",
    "    for len_partial_game in range(1, len_game):\n",
    "        total_nodes += 1\n",
    "        context = game[:len_partial_game]\n",
    "        x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None, ...].to(device)\n",
    "        y = sample(model, x, 1, temperature=1.0)[0]\n",
    "        completion = [train_dataset.itos[int(i)] for i in y]\n",
    "        #completion = [train_dataset.itos[int(i)] for i in y if i != -1]\n",
    "        try:\n",
    "            OthelloBoardState().update(completion, prt=False)\n",
    "        except Exception:\n",
    "            pass\n",
    "        else:\n",
    "            success_nodes += 1\n",
    "    bar.set_description(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")\n",
    "    \n",
    "print(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emergent_world",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
