{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deanhazineh/anaconda3/envs/emergent_world/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3090 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import EWOthello.utils.plot_helpers as plt_util\n",
    "from EWOthello.data.othello import *\n",
    "from EWOthello.mingpt.dataset import ProbingDataset, CharDataset # AK's mingpt data child \n",
    "from EWOthello.mingpt.model import GPT, GPTConfig, GPTforProbing, GPTforProbing_v2\n",
    "from EWOthello.mingpt.utils import set_seed\n",
    "set_seed(44)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.cuda.current_device()\n",
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GPT_Othello(game_dataset, n_layers, n_heads, batch_size=64, num_epochs=100, train_ratio=0.8, val_legal_stepsize=10, num_val=500, save_at_steps=20, learning_rate=1e-4, lr_schedule=False, verbose=False):\n",
    "    model_name = f\"GPT_Synthetic_{n_layers}Layers_{n_heads}Heads\"\n",
    "    savepath = f\"../EWOthello/ckpts/Dean_GPT_Synthetic_{n_layers}L{n_heads}H/\"\n",
    "    mconf = GPTConfig(vocab_size=61, block_size=59, n_layer=n_layers, n_head=n_heads, n_embd=512)\n",
    "    model = GPT(mconf)\n",
    "    model = model.to(device)\n",
    "\n",
    "    training_data = game_dataset\n",
    "    train_size = int(train_ratio * len(training_data))\n",
    "    test_size = len(training_data) - train_size - num_val\n",
    "    val_size = num_val\n",
    "\n",
    "    train_dataset, test_dataset, val_dataset = random_split(training_data, [train_size, test_size, val_size])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "    test_iter = iter(test_dataloader)\n",
    "\n",
    "    warm_up_tokens = train_size*59\n",
    "    warm_up_max = train_size*59*num_epochs\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    training_loss_history = []\n",
    "    testing_loss_history = []\n",
    "    perc_legal_games = []\n",
    "\n",
    "    print(f\"Training Model Name: {model_name}; training/test set size {train_size}/{test_size}; validation games {val_size}\")\n",
    "    if not os.path.exists(savepath):\n",
    "        os.mkdir(savepath)\n",
    "\n",
    "    if os.path.exists(savepath + model_name + \".ckpt\"):\n",
    "        model.load_state_dict(torch.load(savepath + model_name + \".ckpt\"))\n",
    "        print(f\"Loaded model checkpopint from {savepath + model_name + '.ckpt'}\")\n",
    "        with open(savepath + model_name + \".pickle\", 'rb') as fhandle:\n",
    "            training_history = pickle.load(fhandle)\n",
    "            training_loss_history = training_history[\"training_loss\"]\n",
    "            testing_loss_history = training_history[\"testing_loss\"]\n",
    "            perc_legal_games = training_history[\"val_legal_perc\"]\n",
    "\n",
    "    tokens_processed = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        i = 0\n",
    "        for (x,y) in tqdm(train_dataloader):\n",
    "            # Run update training step SGD\n",
    "            model.train()\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            logits, loss = model(x, y)\n",
    "            train_loss = loss.item()\n",
    "            training_loss_history.append(train_loss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the learning rate if using non-fixed scheduler\n",
    "            if lr_schedule:\n",
    "                tokens_processed += (y>=0).sum()\n",
    "                if tokens_processed < warm_up_tokens:\n",
    "                    lr_mult = tokens_processed / warm_up_tokens\n",
    "                else:\n",
    "                    progress = (tokens_processed - warm_up_tokens) / (warm_up_max-warm_up_tokens)\n",
    "                    lr_mult = max(0.1, 0.5*(1 + math.cos(math.pi*progress)))\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group[\"lr\"] = learning_rate * lr_mult\n",
    "\n",
    "            ## Compute the error on test batch\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                try:\n",
    "                    x,y = next(test_iter)\n",
    "                except:\n",
    "                    test_iter = iter(test_dataloader)\n",
    "                    x,y = next(test_iter)\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)        \n",
    "                logits, loss = model(x,y)\n",
    "                test_loss = loss.item()\n",
    "                testing_loss_history.append(test_loss)\n",
    "\n",
    "            ## After a certain number of steps, calculate percent of legal moves the model plays\n",
    "            if i % val_legal_stepsize == 0:\n",
    "                legal_moves_played = 0\n",
    "                for _, (x,y) in enumerate(val_dataloader):\n",
    "                    x = x.to(device)\n",
    "                    logits,_ = model(x)\n",
    "                    moves = torch.argmax(logits, dim=2)[0]\n",
    "                    moves = moves.detach().cpu().numpy()\n",
    "                    x = x.detach().cpu().numpy()\n",
    "                    for len_partial in range(59):\n",
    "                        partial_x = list(x[0,:len_partial])\n",
    "                        partial_x.append(moves[len_partial])\n",
    "                        game_string = [training_data.itos[int(move_idx)] for move_idx in partial_x]\n",
    "                        try:\n",
    "                            OthelloBoardState().update(game_string, prt=False)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                        else:\n",
    "                            legal_moves_played +=1        \n",
    "                perc_legal_games.append(legal_moves_played/val_size/59)\n",
    "            else:\n",
    "                perc_legal_games.append(None)\n",
    "        \n",
    "            ## Save/print\n",
    "            i = i + 1\n",
    "            if verbose:\n",
    "                print(f'step {i}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Val. % Legal Games {legal_games_played/val_size:.3f}')\n",
    "            if (i+1) % save_at_steps == 0:\n",
    "                #print(\"Saving Model Checkpoint\")\n",
    "                torch.save(model.state_dict(), savepath + model_name + \".ckpt\")\n",
    "                training_history = {\"training_loss\": training_loss_history, \"testing_loss\": testing_loss_history, \"val_legal_perc\": perc_legal_games}\n",
    "                with open(savepath + model_name + \".pickle\", 'wb') as fhandle:\n",
    "                    pickle.dump(training_history, fhandle)\n",
    "        \n",
    "        # Save after each epoch also\n",
    "        torch.save(model.state_dict(), savepath + model_name + \".ckpt\")\n",
    "        training_history = {\"training_loss\": training_loss_history, \"testing_loss\": testing_loss_history, \"val_legal_perc\": perc_legal_games}\n",
    "        with open(savepath + model_name + \".pickle\", 'wb') as fhandle:\n",
    "            pickle.dump(training_history, fhandle)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max num files: 230; Use_num: 20\n",
      "['gen10e5__20220324_165952.pickle', 'gen10e5__20220324_154919.pickle', 'gen10e5__20220324_164123.pickle', 'gen10e5__20220324_154043.pickle', 'gen10e5__20220324_155251.pickle', 'gen10e5__20220324_160016.pickle', 'gen10e5__20220324_165748.pickle', 'gen10e5__20220324_154002.pickle', 'gen10e5__20220324_155241.pickle', 'gen10e5__20220324_165707.pickle', 'gen10e5__20220324_160046.pickle', 'gen10e5__20220324_154811.pickle', 'gen10e5__20220324_154806.pickle', 'gen10e5__20220324_162637.pickle', 'gen10e5__20220324_154048.pickle', 'gen10e5__20220324_155439.pickle', 'gen10e5__20220324_155255.pickle', 'gen10e5__20220324_154235.pickle', 'gen10e5__20220324_160049.pickle', 'gen10e5__20220324_154032.pickle']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 1.612 GB: 100%|██████████| 20/20 [00:04<00:00,  4.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplicating...\n",
      "Deduplicating finished with 1999839 games left\n",
      "Using 20 million for training, 0 for validation\n",
      "Dataset created has 1999839 sequences, 61 unique words.\n"
     ]
    }
   ],
   "source": [
    "othello = get(ood_num=-1, data_root=None, num_preload=20) # 11 corresponds to over 1 million games\n",
    "game_dataset = CharDataset(othello) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model Name: GPT_Synthetic_1Layers_8Heads; training/test set size 1599871/399468; validation games 500\n",
      "Loaded model checkpopint from ../EWOthello/ckpts/Dean_GPT_Synthetic_1L8H/GPT_Synthetic_1Layers_8Heads.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [05:17<00:00,  4.93it/s] \n",
      "100%|██████████| 1563/1563 [05:24<00:00,  4.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model Name: GPT_Synthetic_2Layers_8Heads; training/test set size 1599871/399468; validation games 500\n",
      "Loaded model checkpopint from ../EWOthello/ckpts/Dean_GPT_Synthetic_2L8H/GPT_Synthetic_2Layers_8Heads.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [08:01<00:00,  3.25it/s] \n",
      "100%|██████████| 1563/1563 [07:43<00:00,  3.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model Name: GPT_Synthetic_4Layers_8Heads; training/test set size 1599871/399468; validation games 500\n",
      "Loaded model checkpopint from ../EWOthello/ckpts/Dean_GPT_Synthetic_4L8H/GPT_Synthetic_4Layers_8Heads.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1292/1563 [11:06<02:00,  2.25it/s] "
     ]
    }
   ],
   "source": [
    "for num_layers in [1, 2, 4, 8]:\n",
    "    train_GPT_Othello(game_dataset, n_layers=num_layers, n_heads=8, batch_size=1024, learning_rate=1e-4, lr_schedule=False, num_epochs=2, val_legal_stepsize=250, save_at_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_layers in [1, 2, 4, 8]:\n",
    "    train_GPT_Othello(game_dataset, n_layers=num_layers, n_heads=1, batch_size=1024, learning_rate=1e-4, lr_schedule=False, num_epochs=3, val_legal_stepsize=250, save_at_steps=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emergent_world",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
